"""
Question Extractor Service using Google Gemini

Extracts structured exam questions from parsed PDF text:
- Question text and number
- Multiple choice options (A-E or 1-5)
- Correct answer
- Explanation
- Subject and topic metadata
"""

import json
import asyncio
import logging
from typing import Optional, Callable, List, Dict, Any
from dataclasses import dataclass, asdict
import re

from app.core.config import get_settings

logger = logging.getLogger(__name__)

# Try to import Gemini, fall back to mock if not available
try:
    import google.generativeai as genai
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False
    logger.warning("google-generativeai not installed - using mock mode")


@dataclass
class QuestionOption:
    """Single option for a multiple choice question"""
    number: int  # 1-5
    text: str


@dataclass
class ExtractedQuestion:
    """Extracted question with all metadata"""
    question_number: int
    question_text: str
    options: List[QuestionOption]
    correct_answer: int  # 1-5, or 0 if unknown
    explanation: Optional[str] = None
    subject: Optional[str] = None
    topic: Optional[str] = None
    passage: Optional[str] = None  # Context/passage for the question

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for API responses"""
        return {
            "question_number": self.question_number,
            "question_text": self.question_text,
            "options": [{"number": opt.number, "text": opt.text} for opt in self.options],
            "correct_answer": self.correct_answer,
            "explanation": self.explanation,
            "subject": self.subject,
            "topic": self.topic,
            "passage": self.passage,
        }


EXTRACTION_PROMPT = """ë‹¹ì‹ ì€ í•œêµ­ ìžê²©ì¦ ì‹œí—˜ ê¸°ì¶œë¬¸ì œ PDFì—ì„œ ë¬¸ì œë¥¼ ì¶”ì¶œí•˜ëŠ” ì „ë¬¸ê°€ìž…ë‹ˆë‹¤.

ì‹œí—˜ ë¬¸ì œì˜ íŠ¹ì„±:
- ì¼ë¶€ ë¬¸ì œëŠ” **ì§€ë¬¸(passage)**ì´ ë¨¼ì € ì œì‹œë˜ê³ , ê·¸ ì§€ë¬¸ì— ëŒ€í•œ ì—¬ëŸ¬ ë¬¸ì œê°€ ì´ì–´ì§‘ë‹ˆë‹¤
- ì§€ë¬¸ì€ "ë‹¤ìŒ ê¸€ì„ ì½ê³ ", "ë‹¤ìŒì„ ë³´ê³ ", "ë‹¤ìŒ ì¤‘" ë“±ìœ¼ë¡œ ì‹œìž‘í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤
- ì§€ë¬¸ì´ ìžˆëŠ” ê²½ìš° passage í•„ë“œì— ì €ìž¥í•˜ê³ , question_textì—ëŠ” ìˆœìˆ˜í•œ ì§ˆë¬¸ë§Œ í¬í•¨í•˜ì„¸ìš”
- ë…ë¦½ ë¬¸ì œ(ì§€ë¬¸ ì—†ì´ ë°”ë¡œ ì§ˆë¬¸ìœ¼ë¡œ ì‹œìž‘)ë„ ìžˆìŠµë‹ˆë‹¤

ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ì—ì„œ ë‹¤ìŒ ì •ë³´ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”:
1. ë¬¸ì œ ë²ˆí˜¸
2. ì§€ë¬¸ (ìžˆëŠ” ê²½ìš°) - "ë‹¤ìŒ ê¸€ì„ ì½ê³ " ë‹¤ìŒì— ë‚˜ì˜¤ëŠ” ë‚´ìš©
3. ë¬¸ì œ ë‚´ìš© (ì§ˆë¬¸) - ìˆœìˆ˜í•œ ì§ˆë¬¸ë§Œ
4. ë³´ê¸° (1~5ë²ˆ ë˜ëŠ” â‘ ~â‘¤)
5. ì •ë‹µ ë²ˆí˜¸ (ìžˆëŠ” ê²½ìš°)
6. í•´ì„¤ (ìžˆëŠ” ê²½ìš°)
7. ê³¼ëª©ëª… (ìžˆëŠ” ê²½ìš°)
8. ì„¸ë¶€ ì£¼ì œ (ìžˆëŠ” ê²½ìš°)

ë°˜ë“œì‹œ ì•„ëž˜ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”. ë‹¤ë¥¸ í…ìŠ¤íŠ¸ ì—†ì´ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”.

```json
{
  "questions": [
    {
      "question_number": 1,
      "passage": "ì§€ë¬¸ ë‚´ìš© (ì—†ìœ¼ë©´ null)",
      "question_text": "ìˆœìˆ˜í•œ ì§ˆë¬¸ ë‚´ìš©",
      "options": [
        {"number": 1, "text": "ë³´ê¸° 1"},
        {"number": 2, "text": "ë³´ê¸° 2"},
        {"number": 3, "text": "ë³´ê¸° 3"},
        {"number": 4, "text": "ë³´ê¸° 4"},
        {"number": 5, "text": "ë³´ê¸° 5"}
      ],
      "correct_answer": 3,
      "explanation": "í•´ì„¤ ë‚´ìš© (ì—†ìœ¼ë©´ null)",
      "subject": "ê³¼ëª©ëª… (ì—†ìœ¼ë©´ null)",
      "topic": "ì„¸ë¶€ ì£¼ì œ (ì—†ìœ¼ë©´ null)"
    }
  ]
}
```

ì¤‘ìš” ì§€ì¹¨:
- ì§€ë¬¸ê³¼ ë¬¸ì œë¥¼ ì •í™•ížˆ êµ¬ë¶„í•˜ì„¸ìš”
- ë³´ê¸° ë²ˆí˜¸(â‘ â‘¡â‘¢â‘£â‘¤ ë˜ëŠ” 1.2.3.4.5)ë¥¼ 1~5 ìˆ«ìžë¡œ ë³€í™˜í•˜ì„¸ìš”
- ì •ë‹µì´ ëª…ì‹œë˜ì–´ ìžˆì§€ ì•Šìœ¼ë©´ correct_answerë¥¼ 0ìœ¼ë¡œ ì„¤ì •í•˜ì„¸ìš”
- í•´ì„¤ì´ ì—†ìœ¼ë©´ explanationì„ nullë¡œ ì„¤ì •í•˜ì„¸ìš”
- í…ìŠ¤íŠ¸ì—ì„œ ë¬¸ì œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìœ¼ë©´ ë¹ˆ ë°°ì—´ì„ ë°˜í™˜í•˜ì„¸ìš”
- ê°™ì€ ë¬¸ì œ ë²ˆí˜¸ê°€ ì¤‘ë³µë˜ì§€ ì•Šë„ë¡ ì£¼ì˜í•˜ì„¸ìš”

ì¶”ì¶œí•  í…ìŠ¤íŠ¸:
"""


class QuestionExtractor:
    """
    Service for extracting questions from parsed document text.

    Uses Google Gemini 2.5 Flash for fast, accurate extraction.
    Falls back to mock data if API is unavailable.
    """

    MAX_RETRIES = 3
    CHUNK_SIZE = 8000  # Characters per chunk
    GEMINI_MODEL = "gemini-2.0-flash-exp"  # Fast experimental model

    def __init__(self, api_key: Optional[str] = None):
        """
        Initialize question extractor.

        Args:
            api_key: Google API key (defaults to settings if not provided)
        """
        settings = get_settings()
        self.api_key = api_key or settings.google_api_key
        self.use_mock = not self.api_key or not GEMINI_AVAILABLE or settings.dev_mode

        if self.use_mock:
            logger.warning("âš ï¸ Google API key not configured or Gemini unavailable - using MOCK mode")
        else:
            try:
                genai.configure(api_key=self.api_key)
                self.model = genai.GenerativeModel(self.GEMINI_MODEL)
                logger.info(f"âœ… Question extractor initialized with model: {self.GEMINI_MODEL}")
            except Exception as e:
                logger.error(f"Failed to initialize Gemini: {e}")
                self.use_mock = True

    async def extract_questions(
        self,
        text: str,
        progress_callback: Optional[Callable[[int, int, str], Any]] = None,
    ) -> List[ExtractedQuestion]:
        """
        Extract questions from parsed document text.

        Args:
            text: Full document text (from Upstage parser)
            progress_callback: Optional callback(current, total, message)

        Returns:
            List of extracted questions
        """
        if self.use_mock:
            return await self._mock_extract(text, progress_callback)

        logger.info(f"ðŸ“„ Extracting questions from {len(text)} chars")

        # Split into chunks
        chunks = self._split_into_chunks(text)
        logger.info(f"ðŸ“¦ Split into {len(chunks)} chunks")

        all_questions = []

        for i, chunk in enumerate(chunks):
            logger.info(f"ðŸ“¦ Processing chunk {i+1}/{len(chunks)} ({len(chunk)} chars)")

            if progress_callback:
                await progress_callback(i, len(chunks), f"ë¬¸ì œ ì¶”ì¶œ ì¤‘... ({i+1}/{len(chunks)} ì²­í¬)")

            try:
                questions = await self._extract_from_chunk(chunk)
                logger.info(f"âœ… Extracted {len(questions)} questions from chunk {i+1}")
                all_questions.extend(questions)
            except Exception as e:
                logger.error(f"Failed to extract from chunk {i+1}: {e}")
                continue

        # Deduplicate and sort
        unique_questions = self._deduplicate_questions(all_questions)
        unique_questions.sort(key=lambda q: q.question_number)

        logger.info(f"âœ… Total extracted: {len(unique_questions)} unique questions")
        return unique_questions

    def _split_into_chunks(self, text: str) -> List[str]:
        """Split text into chunks while preserving context"""
        if len(text) <= self.CHUNK_SIZE:
            return [text]

        chunks = []
        # Split by page markers first
        pages = re.split(r"---\s*íŽ˜ì´ì§€\s*\d+\s*---", text)

        current_chunk = ""
        for page_text in pages:
            page_text = page_text.strip()
            if not page_text:
                continue

            # If adding this page exceeds chunk size
            if current_chunk and len(current_chunk) + len(page_text) > self.CHUNK_SIZE:
                chunks.append(current_chunk)
                current_chunk = page_text
            else:
                if current_chunk:
                    current_chunk += "\n\n" + page_text
                else:
                    current_chunk = page_text

        # Add remaining chunk
        if current_chunk:
            chunks.append(current_chunk)

        return chunks if chunks else [text]

    async def _extract_from_chunk(self, chunk: str) -> List[ExtractedQuestion]:
        """Extract questions from a single chunk using Gemini"""
        last_error = None

        for attempt in range(self.MAX_RETRIES):
            try:
                response = await self._call_gemini(chunk)
                return self._parse_response(response)

            except Exception as e:
                last_error = e
                logger.warning(f"Gemini API error (attempt {attempt + 1}): {e}")
                await asyncio.sleep(2 * (attempt + 1))

        logger.error(f"Failed after {self.MAX_RETRIES} attempts: {last_error}")
        return []

    async def _call_gemini(self, text: str) -> str:
        """Call Google Gemini API"""
        prompt = EXTRACTION_PROMPT + text

        try:
            # Gemini SDK is sync, run in thread pool
            loop = asyncio.get_event_loop()
            response = await loop.run_in_executor(
                None,
                lambda: self.model.generate_content(
                    prompt,
                    generation_config=genai.types.GenerationConfig(
                        temperature=0.1,
                        max_output_tokens=8192,
                    ),
                    safety_settings=[
                        {"category": cat, "threshold": "BLOCK_NONE"}
                        for cat in [
                            "HARM_CATEGORY_HARASSMENT",
                            "HARM_CATEGORY_HATE_SPEECH",
                            "HARM_CATEGORY_SEXUALLY_EXPLICIT",
                            "HARM_CATEGORY_DANGEROUS_CONTENT",
                        ]
                    ],
                ),
            )

            if not response.text:
                raise ValueError("Empty response from Gemini")

            return response.text

        except Exception as e:
            logger.error(f"Gemini API error: {e}")
            raise

    def _parse_response(self, response_text: str) -> List[ExtractedQuestion]:
        """Parse Gemini JSON response into ExtractedQuestion objects"""
        # Extract JSON from markdown code blocks
        json_str = response_text
        if "```json" in response_text:
            start = response_text.find("```json") + 7
            end = response_text.find("```", start)
            json_str = response_text[start:end].strip()
        elif "```" in response_text:
            start = response_text.find("```") + 3
            end = response_text.find("```", start)
            json_str = response_text[start:end].strip()

        try:
            data = json.loads(json_str)
        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse JSON: {e}")
            logger.error(f"JSON string: {json_str[:500]}")
            return []

        questions = []

        for q in data.get("questions", []):
            try:
                options = [
                    QuestionOption(number=opt["number"], text=opt["text"])
                    for opt in q.get("options", [])
                ]

                question = ExtractedQuestion(
                    question_number=q.get("question_number", 0),
                    question_text=q.get("question_text", ""),
                    options=options,
                    correct_answer=q.get("correct_answer", 0),
                    explanation=q.get("explanation"),
                    subject=q.get("subject"),
                    topic=q.get("topic"),
                    passage=q.get("passage"),
                )
                questions.append(question)
            except Exception as e:
                logger.error(f"Failed to parse question: {e}")
                continue

        return questions

    def _deduplicate_questions(
        self,
        questions: List[ExtractedQuestion]
    ) -> List[ExtractedQuestion]:
        """Remove duplicate questions by question number"""
        seen = {}
        for q in questions:
            key = q.question_number
            if key not in seen or (q.correct_answer > 0 and seen[key].correct_answer == 0):
                # Prefer questions with known answers
                seen[key] = q
        return list(seen.values())

    async def _mock_extract(
        self,
        text: str,
        progress_callback: Optional[Callable] = None,
    ) -> List[ExtractedQuestion]:
        """Mock extraction for testing"""
        logger.warning("ðŸ”§ MOCK: Using mock question extraction")

        await asyncio.sleep(1.0)

        if progress_callback:
            await progress_callback(1, 1, "Mock ë°ì´í„° ìƒì„± ì¤‘...")

        mock_questions = [
            ExtractedQuestion(
                question_number=1,
                question_text="ì‚¬íšŒë³µì§€ì˜ ê¸°ë³¸ ì›ì¹™ì— ëŒ€í•œ ì„¤ëª…ìœ¼ë¡œ ì˜³ì€ ê²ƒì€?",
                options=[
                    QuestionOption(1, "ì‚¬íšŒë³µì§€ëŠ” ì„ ë³„ì  ì„œë¹„ìŠ¤ë¥¼ ì›ì¹™ìœ¼ë¡œ í•œë‹¤"),
                    QuestionOption(2, "ì‚¬íšŒë³µì§€ëŠ” ìž”ì—¬ì  ê°œë…ì— ê¸°ì´ˆí•œë‹¤"),
                    QuestionOption(3, "ì‚¬íšŒë³µì§€ëŠ” ë³´íŽ¸ì  ì„œë¹„ìŠ¤ë¥¼ ì§€í–¥í•œë‹¤"),
                    QuestionOption(4, "ì‚¬íšŒë³µì§€ëŠ” ì‹œìž¥ ì›ë¦¬ì— ë”°ë¼ ìš´ì˜ëœë‹¤"),
                    QuestionOption(5, "ì‚¬íšŒë³µì§€ëŠ” ê°œì¸ì˜ ì±…ìž„ì„ ê°•ì¡°í•œë‹¤"),
                ],
                correct_answer=3,
                explanation="í˜„ëŒ€ ì‚¬íšŒë³µì§€ëŠ” ë³´íŽ¸ì  ì„œë¹„ìŠ¤ë¥¼ ì§€í–¥í•˜ë©°, ëª¨ë“  êµ­ë¯¼ì˜ ê¸°ë³¸ì  ê¶Œë¦¬ë¥¼ ë³´ìž¥í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•œë‹¤.",
                subject="ì‚¬íšŒë³µì§€ê¸°ì´ˆ",
                topic="ì‚¬íšŒë³µì§€ì˜ ê°œë…",
            ),
            ExtractedQuestion(
                question_number=2,
                question_text="ë‹¤ìŒ ì¤‘ ì‚¬íšŒë³µì§€ ì‹¤ì²œì˜ ê°€ì¹˜ë¡œ ì ì ˆí•˜ì§€ ì•Šì€ ê²ƒì€?",
                options=[
                    QuestionOption(1, "ì¸ê°„ì˜ ì¡´ì—„ì„±"),
                    QuestionOption(2, "ìžê¸°ê²°ì •ê¶Œ"),
                    QuestionOption(3, "ì°¨ë³„ê³¼ ë°°ì œ"),
                    QuestionOption(4, "ì‚¬íšŒì •ì˜"),
                    QuestionOption(5, "í‰ë“±"),
                ],
                correct_answer=3,
                explanation="ì°¨ë³„ê³¼ ë°°ì œëŠ” ì‚¬íšŒë³µì§€ ì‹¤ì²œì˜ ê°€ì¹˜ê°€ ì•„ë‹ˆë¼ ê·¹ë³µí•´ì•¼ í•  ëŒ€ìƒì´ë‹¤.",
                subject="ì‚¬íšŒë³µì§€ê¸°ì´ˆ",
                topic="ì‚¬íšŒë³µì§€ ì‹¤ì²œ ê°€ì¹˜",
            ),
        ]

        return mock_questions


# Singleton instance
_question_extractor: Optional[QuestionExtractor] = None


def get_question_extractor() -> QuestionExtractor:
    """Get or create singleton question extractor instance"""
    global _question_extractor
    if _question_extractor is None:
        _question_extractor = QuestionExtractor()
    return _question_extractor
