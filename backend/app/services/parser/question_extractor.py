"""AI-powered question extraction using Google Gemini.

Extracts structured questions from parsed PDF text,
including question text, options, correct answers, and explanations.
"""

import json
import asyncio
from typing import Any
from dataclasses import dataclass, asdict
import logging
import google.generativeai as genai

from app.core.config import get_settings
from app.core.exceptions import ServerInternalError

logger = logging.getLogger(__name__)


@dataclass
class QuestionOption:
    """Represents a single option for a question."""
    number: int  # 1-5
    text: str


@dataclass
class ExtractedQuestion:
    """Represents an extracted question from the exam."""
    question_number: int
    question_text: str
    options: list[QuestionOption]
    correct_answer: int  # 1-5
    explanation: str | None = None
    subject: str | None = None  # Í≥ºÎ™©
    topic: str | None = None  # ÏÑ∏Î∂Ä Ï£ºÏ†ú


EXTRACTION_PROMPT = """ÎãπÏã†ÏùÄ ÏÇ¨ÌöåÎ≥µÏßÄÏÇ¨ 1Í∏â ÏãúÌóò Í∏∞Ï∂úÎ¨∏Ï†ú PDFÏóêÏÑú Î¨∏Ï†úÎ•º Ï∂îÏ∂úÌïòÎäî Ï†ÑÎ¨∏Í∞ÄÏûÖÎãàÎã§.

ÏãúÌóò Î¨∏Ï†úÏùò ÌäπÏÑ±:
- ÏùºÎ∂Ä Î¨∏Ï†úÎäî **ÏßÄÎ¨∏(passage)**Ïù¥ Î®ºÏ†Ä Ï†úÏãúÎêòÍ≥†, Í∑∏ ÏßÄÎ¨∏Ïóê ÎåÄÌïú Ïó¨Îü¨ Î¨∏Ï†úÍ∞Ä Ïù¥Ïñ¥ÏßëÎãàÎã§
- ÏßÄÎ¨∏ÏùÄ "Îã§Ïùå Í∏ÄÏùÑ ÏùΩÍ≥†", "Îã§ÏùåÏùÑ Î≥¥Í≥†" Îì±ÏúºÎ°ú ÏãúÏûëÌï©ÎãàÎã§
- ÏßÄÎ¨∏ Í¥ÄÎ†® Î¨∏Ï†úÏùò question_textÏóêÎäî **ÏßÄÎ¨∏ ÎÇ¥Ïö©ÏùÑ Ìè¨Ìï®ÌïòÏßÄ ÎßàÏÑ∏Ïöî**. ÏàúÏàòÌïú ÏßàÎ¨∏Îßå Ï∂îÏ∂úÌïòÏÑ∏Ïöî
- ÎèÖÎ¶Ω Î¨∏Ï†ú(ÏßÄÎ¨∏ ÏóÜÏù¥ Î∞îÎ°ú ÏßàÎ¨∏ÏúºÎ°ú ÏãúÏûë)ÎèÑ ÏûàÏäµÎãàÎã§

Ï£ºÏñ¥ÏßÑ ÌÖçÏä§Ìä∏ÏóêÏÑú Îã§Ïùå Ï†ïÎ≥¥Î•º Ï∂îÏ∂úÌï¥Ï£ºÏÑ∏Ïöî:
1. Î¨∏Ï†ú Î≤àÌò∏
2. Î¨∏Ï†ú ÎÇ¥Ïö© (ÏßàÎ¨∏) - **ÏßÄÎ¨∏ Ï†úÏô∏, ÏßàÎ¨∏Îßå**
3. Î≥¥Í∏∞ (1~5Î≤à)
4. Ï†ïÎãµ Î≤àÌò∏
5. Ìï¥ÏÑ§ (ÏûàÎäî Í≤ΩÏö∞)
6. Í≥ºÎ™©Î™Ö (ÏÇ¨ÌöåÎ≥µÏßÄÍ∏∞Ï¥à, ÏÇ¨ÌöåÎ≥µÏßÄÏã§Ï≤ú, ÏÇ¨ÌöåÎ≥µÏßÄÏ†ïÏ±ÖÍ≥ºÏ†úÎèÑ Îì±)
7. ÏÑ∏Î∂Ä Ï£ºÏ†ú (ÏûàÎäî Í≤ΩÏö∞)

Î∞òÎìúÏãú ÏïÑÎûò JSON ÌòïÏãùÏúºÎ°ú ÏùëÎãµÌï¥Ï£ºÏÑ∏Ïöî. Îã§Î•∏ ÌÖçÏä§Ìä∏ ÏóÜÏù¥ JSONÎßå Ï∂úÎ†•ÌïòÏÑ∏Ïöî.

```json
{
  "questions": [
    {
      "question_number": 1,
      "question_text": "Î¨∏Ï†ú ÎÇ¥Ïö© (ÏàúÏàòÌïú ÏßàÎ¨∏Îßå, ÏßÄÎ¨∏ Ï†úÏô∏)",
      "options": [
        {"number": 1, "text": "Î≥¥Í∏∞ 1"},
        {"number": 2, "text": "Î≥¥Í∏∞ 2"},
        {"number": 3, "text": "Î≥¥Í∏∞ 3"},
        {"number": 4, "text": "Î≥¥Í∏∞ 4"},
        {"number": 5, "text": "Î≥¥Í∏∞ 5"}
      ],
      "correct_answer": 3,
      "explanation": "Ìï¥ÏÑ§ ÎÇ¥Ïö© (ÏóÜÏúºÎ©¥ null)",
      "subject": "Í≥ºÎ™©Î™Ö",
      "topic": "ÏÑ∏Î∂Ä Ï£ºÏ†ú (ÏóÜÏúºÎ©¥ null)"
    }
  ]
}
```

Ï§ëÏöî ÏßÄÏπ®:
- **ÏßÄÎ¨∏Í≥º Î¨∏Ï†úÎ•º Íµ¨Î∂Ñ**ÌïòÏÑ∏Ïöî. ÏßÄÎ¨∏ÏùÄ question_textÏóê Ìè¨Ìï®ÌïòÏßÄ ÎßàÏÑ∏Ïöî
- Î¨∏Ï†úÏôÄ Î≥¥Í∏∞Î•º Ï†ïÌôïÌûà Íµ¨Î∂ÑÌïòÏÑ∏Ïöî
- Î≥¥Í∏∞ Î≤àÌò∏(‚ë†‚ë°‚ë¢‚ë£‚ë§ ÎòêÎäî 1.2.3.4.5)Î•º 1~5 Ïà´ÏûêÎ°ú Î≥ÄÌôòÌïòÏÑ∏Ïöî
- Ï†ïÎãµÏù¥ Î™ÖÏãúÎêòÏñ¥ ÏûàÏßÄ ÏïäÏúºÎ©¥ correct_answerÎ•º 0ÏúºÎ°ú ÏÑ§Ï†ïÌïòÏÑ∏Ïöî
- Ìï¥ÏÑ§Ïù¥ ÏóÜÏúºÎ©¥ explanationÏùÑ nullÎ°ú ÏÑ§Ï†ïÌïòÏÑ∏Ïöî
- ÌÖçÏä§Ìä∏ÏóêÏÑú Î¨∏Ï†úÎ•º Ï∞æÏùÑ Ïàò ÏóÜÏúºÎ©¥ Îπà Î∞∞Ïó¥ÏùÑ Î∞òÌôòÌïòÏÑ∏Ïöî

Ï∂îÏ∂úÌï† ÌÖçÏä§Ìä∏:
"""


class QuestionExtractor:
    """Service for extracting questions from parsed document text using Google Gemini."""

    MAX_RETRIES = 3
    CHUNK_SIZE = 5000  # Reduced to avoid Gemini safety filter issues

    def __init__(self):
        self.settings = get_settings()
        self.api_key = self.settings.google_api_key

        # Configure Gemini API
        genai.configure(api_key=self.api_key)

        # Use Gemini 2.5 Flash for fast, cost-effective processing
        # Supports up to 1M tokens, stable release
        self.model = genai.GenerativeModel('gemini-2.5-flash')

    async def extract_questions(
        self,
        text: str,
        on_progress: callable = None,
    ) -> list[ExtractedQuestion]:
        """
        Extract questions from document text.

        Args:
            text: Full document text from Upstage parser
            on_progress: Optional callback for progress updates

        Returns:
            List of extracted questions
        """
        # Log the input text for debugging
        logger.info(f"üìÑ Input text length: {len(text)} characters")
        logger.info(f"üìÑ First 500 chars: {text[:500]}")
        logger.info(f"üìÑ Last 500 chars: {text[-500:]}")

        # Split text into chunks if too long
        chunks = self._split_into_chunks(text)
        logger.info(f"üì¶ Split into {len(chunks)} chunks")

        all_questions = []

        for i, chunk in enumerate(chunks):
            logger.info(f"üì¶ Chunk {i+1}/{len(chunks)}: {len(chunk)} characters")
            logger.info(f"üì¶ Chunk {i+1} preview (first 300 chars): {chunk[:300]}")

            if on_progress:
                progress = int((i / len(chunks)) * 100)
                await on_progress(progress, f"Î¨∏Ï†ú Ï∂îÏ∂ú Ï§ë... ({i+1}/{len(chunks)})")

            try:
                questions = await self._extract_from_chunk(chunk)
                logger.info(f"‚úÖ Extracted {len(questions)} questions from chunk {i+1}")
                all_questions.extend(questions)
            except Exception as e:
                logger.error(f"Failed to extract from chunk {i}: {e}")
                continue

        # Deduplicate and sort by question number
        unique_questions = self._deduplicate_questions(all_questions)
        unique_questions.sort(key=lambda q: q.question_number)

        return unique_questions

    def _split_into_chunks(self, text: str) -> list[str]:
        """
        Split text into processable chunks while preserving passage-question relationships.

        Strategy:
        1. Identify page boundaries (ÌéòÏù¥ÏßÄ markers)
        2. Keep passages and their questions together
        3. Split at page boundaries when possible
        """
        if len(text) <= self.CHUNK_SIZE:
            return [text]

        chunks = []
        # Split by page markers first to maintain page structure
        pages = text.split("--- ÌéòÏù¥ÏßÄ")

        current_chunk = ""

        for page_text in pages:
            page_text = page_text.strip()
            if not page_text:
                continue

            # If adding this page would exceed chunk size
            if current_chunk and len(current_chunk) + len(page_text) > self.CHUNK_SIZE:
                # Save current chunk and start new one
                chunks.append(current_chunk)
                current_chunk = page_text
            else:
                # Add to current chunk
                if current_chunk:
                    current_chunk += "\n--- ÌéòÏù¥ÏßÄ" + page_text
                else:
                    current_chunk = page_text

        # Add remaining chunk
        if current_chunk:
            chunks.append(current_chunk)

        return chunks if chunks else [text]

    async def _extract_from_chunk(self, chunk: str) -> list[ExtractedQuestion]:
        """Extract questions from a single text chunk using Google Gemini."""
        last_error = None

        for attempt in range(self.MAX_RETRIES):
            try:
                response = await self._call_gemini(chunk)
                return self._parse_response(response)

            except Exception as e:
                last_error = e
                logger.warning(f"Gemini API error (attempt {attempt + 1}): {e}")
                await asyncio.sleep(2 * (attempt + 1))

        logger.error(f"Failed to extract questions after {self.MAX_RETRIES} attempts: {last_error}")
        return []

    async def _call_gemini(self, text: str) -> str:
        """Make API call to Google Gemini."""
        prompt = EXTRACTION_PROMPT + text

        logger.info(f"üì§ Sending Gemini API request with model: {self.model._model_name}")
        logger.debug(f"üì§ Prompt length: {len(prompt)} characters")

        try:
            # Gemini SDK is synchronous, so we run it in a thread pool
            loop = asyncio.get_event_loop()
            response = await loop.run_in_executor(
                None,
                lambda: self.model.generate_content(
                    prompt,
                    generation_config=genai.types.GenerationConfig(
                        temperature=0.1,
                        max_output_tokens=4096,
                    ),
                    # Disable ALL safety filters for educational content
                    safety_settings=[
                        {
                            "category": "HARM_CATEGORY_HARASSMENT",
                            "threshold": "BLOCK_NONE"
                        },
                        {
                            "category": "HARM_CATEGORY_HATE_SPEECH",
                            "threshold": "BLOCK_NONE"
                        },
                        {
                            "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
                            "threshold": "BLOCK_NONE"
                        },
                        {
                            "category": "HARM_CATEGORY_DANGEROUS_CONTENT",
                            "threshold": "BLOCK_NONE"
                        }
                    ]
                )
            )

            # Check if response was blocked
            if hasattr(response, 'candidates') and response.candidates:
                candidate = response.candidates[0]
                if hasattr(candidate, 'finish_reason'):
                    if candidate.finish_reason == 2:  # SAFETY
                        logger.warning("‚ö†Ô∏è Gemini response blocked by safety filter - using fallback")
                        # Try to get partial content or use a simpler approach
                        if hasattr(candidate, 'content') and candidate.content:
                            return str(candidate.content)

            if not response.text:
                raise ValueError("Empty response from Gemini API")

            logger.info(f"‚úÖ Gemini API response received: {len(response.text)} characters")
            logger.debug(f"üì• Response preview: {response.text[:500]}")

            return response.text

        except Exception as e:
            logger.error(f"‚ùå Gemini API error: {str(e)}")
            logger.error(f"API key configured: {'Yes' if self.api_key else 'No'}")

            # If blocked by safety, return empty list to avoid crash
            if "finish_reason" in str(e) and "is 2" in str(e):
                logger.warning("Content blocked by Gemini safety filter - returning empty result")
                return "[]"  # Return empty JSON array
            raise

    def _parse_response(self, response_text: str) -> list[ExtractedQuestion]:
        """Parse Gemini response into ExtractedQuestion objects."""
        # Extract JSON from response (handle markdown code blocks)
        json_str = response_text
        if "```json" in response_text:
            start = response_text.find("```json") + 7
            end = response_text.find("```", start)
            json_str = response_text[start:end].strip()
        elif "```" in response_text:
            start = response_text.find("```") + 3
            end = response_text.find("```", start)
            json_str = response_text[start:end].strip()

        try:
            data = json.loads(json_str)
        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse JSON: {e}")
            logger.error(f"JSON string: {json_str[:500]}")
            raise

        questions = []

        for q in data.get("questions", []):
            options = [
                QuestionOption(number=opt["number"], text=opt["text"])
                for opt in q.get("options", [])
            ]

            question = ExtractedQuestion(
                question_number=q.get("question_number", 0),
                question_text=q.get("question_text", ""),
                options=options,
                correct_answer=q.get("correct_answer", 0),
                explanation=q.get("explanation"),
                subject=q.get("subject"),
                topic=q.get("topic"),
            )
            questions.append(question)

        return questions

    def _deduplicate_questions(
        self,
        questions: list[ExtractedQuestion]
    ) -> list[ExtractedQuestion]:
        """Remove duplicate questions based on question number."""
        seen = {}
        for q in questions:
            key = q.question_number
            if key not in seen or (q.correct_answer > 0 and seen[key].correct_answer == 0):
                # Prefer questions with known correct answers
                seen[key] = q
        return list(seen.values())

    def to_db_format(self, question: ExtractedQuestion) -> dict[str, Any]:
        """Convert ExtractedQuestion to database format."""
        return {
            "question_number": question.question_number,
            "question_text": question.question_text,
            "options": [asdict(opt) for opt in question.options],
            "correct_answer": question.correct_answer,
            "explanation": question.explanation,
            "subject": question.subject,
            "topic": question.topic,
        }

    async def extract_with_llm(self, text: str) -> list[dict[str, Any]]:
        """
        Extract questions using LLM (Google Gemini).

        Args:
            text: Full document text (markdown)

        Returns:
            List of questions in database format
        """
        questions = await self.extract_questions(text)
        return [self.to_db_format(q) for q in questions]

    def extract_with_rules(self, text: str) -> list[dict[str, Any]]:
        """
        Extract questions using rule-based parsing.

        Fallback for when no LLM API is available.

        Args:
            text: Full document text

        Returns:
            List of questions in database format
        """
        import re

        questions = []
        # Pattern: Î¨∏Ï†ú Î≤àÌò∏ + ÎÇ¥Ïö© + Î≥¥Í∏∞Îì§
        question_pattern = r'(\d{1,3})\.\s+(.+?)(?=\d{1,3}\.\s+|\Z)'
        option_pattern = r'[‚ë†‚ë°‚ë¢‚ë£‚ë§]\s*(.+?)(?=[‚ë†‚ë°‚ë¢‚ë£‚ë§]|\Z)'

        matches = re.findall(question_pattern, text, re.DOTALL)

        for num_str, content in matches:
            q_num = int(num_str)
            content = content.strip()

            # Split question text and options
            parts = content.split('\n')
            question_text = parts[0] if parts else ""

            # Extract options
            options = []
            option_markers = ['‚ë†', '‚ë°', '‚ë¢', '‚ë£', '‚ë§']
            for i, marker in enumerate(option_markers, 1):
                if marker in content:
                    start = content.find(marker) + 1
                    end = len(content)
                    for next_marker in option_markers[i:]:
                        next_pos = content.find(next_marker)
                        if next_pos != -1 and next_pos < end:
                            end = next_pos
                    opt_text = content[start:end].strip()
                    options.append({"number": i, "text": opt_text})

            if question_text and len(options) >= 2:
                questions.append({
                    "question_number": q_num,
                    "question_text": question_text,
                    "options": options,
                    "correct_answer": 0,  # Unknown without answer key
                    "explanation": None,
                    "subject": None,
                    "topic": None,
                })

        return questions
