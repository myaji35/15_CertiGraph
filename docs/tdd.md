# Test-Driven Development (TDD) Guide

**Project:** CertiGraph (AI ìê²©ì¦ ë§ˆìŠ¤í„°)
**Last Updated:** 2026-01-15
**Version:** 1.0.0

---

## Overview

This guide establishes Test-Driven Development practices for CertiGraph, with emphasis on parallel test execution, intelligent test grouping, and systematic bug resolution workflows.

## Core TDD Principles

### ğŸš¨ í™©ê¸ˆ ê·œì¹™: ëê¹Œì§€ í…ŒìŠ¤íŠ¸ ì‹¤í–‰

**CRITICAL: ëª¨ë“  ì‘ì—… í›„ ë°˜ë“œì‹œ í…ŒìŠ¤íŠ¸ë¥¼ ëê¹Œì§€ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ í™•ì¸í•  ê²ƒ!**

```
âŒ ì˜ëª»ëœ ë°©ì‹:
1. ì½”ë“œ ìˆ˜ì •
2. "ìˆ˜ì • ì™„ë£Œ" ë³´ê³ 
3. í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì•ˆí•¨ â† ìœ„í—˜!

âœ… ì˜¬ë°”ë¥¸ ë°©ì‹:
1. ì½”ë“œ ìˆ˜ì •
2. í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ëê¹Œì§€!)
3. ê²°ê³¼ í™•ì¸ ë° ë³´ê³ 
4. ì‹¤íŒ¨ ì‹œ ìˆ˜ì • ë°˜ë³µ
```

**ì´ ê·œì¹™ì„ ì–´ê¸°ë©´:**
- ğŸ”¥ ìˆ¨ê²¨ì§„ ë²„ê·¸ ë°œìƒ
- ğŸ”¥ íšŒê·€(Regression) ì˜¤ë¥˜
- ğŸ”¥ í”„ë¡œë•ì…˜ ì¥ì•  ê°€ëŠ¥ì„±

**ë°˜ë“œì‹œ í™•ì¸í•´ì•¼ í•  ê²ƒ:**
1. âœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ê°€ **ì‹¤ì œë¡œ ì‹¤í–‰**ë˜ì—ˆëŠ”ê°€?
2. âœ… ì‹¤í–‰ ê²°ê³¼ë¥¼ **ëê¹Œì§€ í™•ì¸**í–ˆëŠ”ê°€?
3. âœ… ì‹¤íŒ¨í•œ í…ŒìŠ¤íŠ¸ê°€ **ì—†ëŠ”ì§€** ê²€ì¦í–ˆëŠ”ê°€?
4. âœ… ê²°ê³¼ ë¦¬í¬íŠ¸ë¥¼ **ë¬¸ì„œí™”**í–ˆëŠ”ê°€?

---

### Red-Green-Refactor Cycle

```mermaid
flowchart LR
    Red[Write Failing Test] --> Green[Write Minimal Code]
    Green --> Pass{Test Passes?}
    Pass -->|No| Green
    Pass -->|Yes| Refactor[Refactor Code]
    Refactor --> Verify[Verify Tests Pass]
    Verify --> Red
```

1. **Red:** Write a failing test that defines desired behavior
2. **Green:** Write minimal code to make the test pass
3. **Refactor:** Improve code quality while keeping tests green

**âš ï¸ ì£¼ì˜: ê° ë‹¨ê³„ë§ˆë‹¤ í…ŒìŠ¤íŠ¸ë¥¼ ëê¹Œì§€ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ í™•ì¸í•  ê²ƒ!**

---

## Test Organization Strategy

### Test Categories

Organize tests into these categories for parallel execution:

```markdown
test/
â”œâ”€â”€ unit/                    # Fast, isolated tests
â”‚   â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ services/
â”‚   â””â”€â”€ helpers/
â”œâ”€â”€ integration/             # Component interaction tests
â”‚   â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ database/
â”‚   â””â”€â”€ graph/
â”œâ”€â”€ system/                  # End-to-end workflows
â”‚   â”œâ”€â”€ auth_flows/
â”‚   â”œâ”€â”€ test_sessions/
â”‚   â””â”€â”€ recommendations/
â””â”€â”€ performance/             # Load and stress tests
    â”œâ”€â”€ api_benchmarks/
    â””â”€â”€ graph_queries/
```

### Test Grouping Rules

**Parallel-Safe Groups** (can run simultaneously):

- **Group A - Read-Only:** Tests that only query data
- **Group B - Isolated Data:** Tests with unique fixture data
- **Group C - Unit Tests:** Pure logic tests without I/O
- **Group D - External Services:** Tests with mocked APIs

**Sequential Groups** (must run serially):

- **Group S1 - Database Mutations:** Tests that modify shared data
- **Group S2 - File System:** Tests that create/delete files
- **Group S3 - Authentication:** Tests that modify session state
- **Group S4 - Background Jobs:** Tests that enqueue/process jobs

---

## Parallel Test Execution

### Configuration

```ruby
# test/test_helper.rb
ENV['RAILS_ENV'] ||= 'test'
require_relative '../config/environment'
require 'rails/test_help'

class ActiveSupport::TestCase
  # Use parallel testing
  parallelize(workers: :number_of_processors)

  # Ensure clean state between tests
  parallelize_setup do |worker|
    SimpleCov.command_name "#{SimpleCov.command_name}-#{worker}"
  end

  parallelize_teardown do |worker|
    SimpleCov.result
  end

  fixtures :all
end
```

### Running Parallel Tests

```bash
# Run all tests in parallel
rails test

# Run specific group in parallel
rails test test/unit/

# Run single file (no parallelization needed)
rails test test/models/user_test.rb

# Run with specific worker count
PARALLEL_WORKERS=4 rails test
```

### Grouping by Isolation Level

```ruby
# test/test_groups.rb
module TestGroups
  PARALLEL_SAFE = [
    'test/unit/**/*_test.rb',
    'test/services/**/*_test.rb',
    'test/helpers/**/*_test.rb'
  ]

  SEQUENTIAL_ONLY = [
    'test/integration/database/**/*_test.rb',
    'test/system/**/*_test.rb'
  ]

  def self.run_parallel_safe
    PARALLEL_SAFE.each do |pattern|
      Dir.glob(pattern).each { |file| require file }
    end
  end
end
```

---

## Bug Fix Workflow

### Standard Bug Resolution Process

```mermaid
flowchart TD
    Bug[Bug Discovered] --> Repro[Write Failing Test]
    Repro --> Verify[Verify Test Fails]
    Verify --> Fix[Implement Fix]
    Fix --> Single[Run Single Test]
    Single --> Pass{Test Passes?}
    Pass -->|No| Debug[Debug & Iterate]
    Debug --> Fix
    Pass -->|Yes| Group[Run Test Group]
    Group --> GroupPass{Group Passes?}
    GroupPass -->|No| Regression[Fix Regression]
    Regression --> Group
    GroupPass -->|Yes| Full[Run Full Suite]
    Full --> FullPass{All Pass?}
    FullPass -->|No| Conflict[Resolve Conflicts]
    Conflict --> Full
    FullPass -->|Yes| Done[Commit Fix]
```

### Step-by-Step Bug Fix Protocol

**âš ï¸ ì¤‘ìš”: ê° ë‹¨ê³„ë§ˆë‹¤ í…ŒìŠ¤íŠ¸ë¥¼ ëê¹Œì§€ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ í™•ì¸í•´ì•¼ í•©ë‹ˆë‹¤!**

#### 1. Reproduce the Bug

Create a failing test that demonstrates the issue:

```ruby
# test/models/user_test.rb
test "should handle nil email gracefully" do
  user = User.new(email: nil)
  assert user.valid?, "User with nil email should be valid"
end
```

**Verify the test fails:**

```bash
rails test test/models/user_test.rb
# Expected: Test should FAIL (Red phase)
# âœ… ë°˜ë“œì‹œ ì‹¤í–‰í•˜ê³  ì‹¤íŒ¨ë¥¼ í™•ì¸í•  ê²ƒ!
```

#### 2. Implement the Fix

Write minimal code to fix the issue:

```ruby
# app/models/user.rb
class User < ApplicationRecord
  validates :email, presence: true, allow_nil: true

  def email=(value)
    super(value&.strip&.downcase)
  end
end
```

#### 3. Run Single Test

**ğŸš¨ CRITICAL: ë°˜ë“œì‹œ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ í™•ì¸í•  ê²ƒ!**

```bash
rails test test/models/user_test.rb
# Expected: Test should PASS (Green phase)
# âœ… í†µê³¼ í™•ì¸ í•„ìˆ˜!
```

#### 4. Run Related Test Group

**ğŸš¨ CRITICAL: íšŒê·€ ì˜¤ë¥˜ ê²€ì¦ í•„ìˆ˜!**

```bash
# Run all model tests
rails test test/models/

# Check for regressions
echo $?  # Should be 0 (success)
# âœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ê°€ í†µê³¼í•˜ëŠ”ì§€ í™•ì¸í•  ê²ƒ!
```

#### 5. Run Full Test Suite

**ğŸš¨ CRITICAL: ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ë° ê²°ê³¼ í™•ì¸ í•„ìˆ˜!**

```bash
# Run everything
rails test

# âœ… ëê¹Œì§€ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ í™•ì¸í•  ê²ƒ!
# If failures occur, identify conflicts
rails test --verbose | grep FAIL
```

**âš ï¸ ì£¼ì˜ì‚¬í•­:**
- í…ŒìŠ¤íŠ¸ ì‹¤í–‰ì„ ì¤‘ë‹¨í•˜ì§€ ë§ ê²ƒ
- "ì•„ë§ˆ ê´œì°®ì„ ê²ƒ"ì´ë¼ê³  ì¶”ì¸¡í•˜ì§€ ë§ ê²ƒ
- ë°˜ë“œì‹œ ì‹¤ì œ ê²°ê³¼ë¥¼ í™•ì¸í•  ê²ƒ

#### 6. Resolve Conflicts

If other tests fail:

1. Identify affected tests
2. Determine if fix introduced regression
3. Update fix or tests as needed
4. Return to step 3

---

## Cache Management Protocol

**Critical:** Rails caches can cause false test results. Follow this protocol after any code change:

### 1. Clear All Caches

```bash
# Kill all running processes
pkill -f rails
pkill -f puma
pkill -f sidekiq

# Clear all cache directories
rm -rf tmp/cache/*
rm -rf rails-api/tmp/cache/*
rm -rf storage/development.sqlite3-shm
rm -rf storage/development.sqlite3-wal

# Clear test cache
rails test:prepare
```

### 2. Verify File Changes

```bash
# Confirm file was actually saved
cat [modified_file_path] | grep -A 5 "changed_section"
```

### 3. Clean Restart

```bash
# Start fresh server
rails server -p 3000
```

### 4. Run Tests

```bash
# Now run your tests
rails test
```

**Never skip cache clearing.** Cached code will cause inconsistent test results.

---

## Test Data Management

### Fixtures vs Factories

**Use Fixtures for:**

- Stable reference data
- Parallel-safe read-only tests
- Fast test setup

**Use Factories for:**

- Dynamic test scenarios
- Integration tests with complex data
- Tests requiring unique data per run

### Fixture Isolation

```ruby
# test/fixtures/users.yml
# Each test worker gets isolated data
user_<%= worker_id %>_1:
  email: "user<%= worker_id %>_1@example.com"
  name: "Test User <%= worker_id %>"
```

### Factory Pattern

```ruby
# test/factories/users.rb
FactoryBot.define do
  factory :user do
    sequence(:email) { |n| "user#{n}@example.com" }
    name { Faker::Name.name }

    trait :with_test_sessions do
      after(:create) do |user|
        create_list(:test_session, 3, user: user)
      end
    end
  end
end
```

---

## Test Isolation Techniques

### Database Transactions

```ruby
class ActiveSupport::TestCase
  # Wrap each test in transaction
  self.use_transactional_tests = true

  # Clean state before each test
  setup do
    DatabaseCleaner.start
  end

  teardown do
    DatabaseCleaner.clean
  end
end
```

### File System Isolation

```ruby
class FileUploadTest < ActiveSupport::TestCase
  setup do
    @test_dir = Rails.root.join('tmp', 'test_uploads', SecureRandom.uuid)
    FileUtils.mkdir_p(@test_dir)
  end

  teardown do
    FileUtils.rm_rf(@test_dir)
  end

  test "uploads study material PDF" do
    file = fixture_file_upload('sample.pdf', 'application/pdf')
    # Test uses @test_dir for isolation
  end
end
```

### API Mock Isolation

```ruby
class Neo4jServiceTest < ActiveSupport::TestCase
  setup do
    @stub = stub_request(:post, "https://neo4j.example.com/db/data/transaction/commit")
      .with(body: hash_including(statements: anything))
      .to_return(status: 200, body: '{"results":[]}')
  end

  teardown do
    WebMock.reset!
  end

  test "creates knowledge node" do
    Neo4jService.create_node(type: 'Concept', name: 'TDD')
    assert_requested @stub
  end
end
```

---

## Debugging Failed Tests

### Systematic Debugging Approach

```mermaid
flowchart TD
    Fail[Test Fails] --> Read[Read Error Message]
    Read --> Type{Error Type?}
    Type -->|Assertion| Logic[Check Test Logic]
    Type -->|Exception| Stack[Review Stack Trace]
    Type -->|Timeout| Perf[Check Performance]
    Logic --> Fix[Apply Fix]
    Stack --> Fix
    Perf --> Fix
    Fix --> Retest[Run Test Again]
    Retest --> Pass{Passes?}
    Pass -->|No| Debug[Add Debug Output]
    Debug --> Read
    Pass -->|Yes| Verify[Run Group Tests]
```

### Debug Techniques

**1. Add Debug Output:**

```ruby
test "calculates mastery score correctly" do
  user = users(:learner)

  # Debug current state
  puts "User: #{user.inspect}"
  puts "Masteries: #{user.user_masteries.count}"

  score = user.calculate_mastery_score

  puts "Calculated score: #{score}"

  assert_equal 0.75, score
end
```

**2. Use Minitest Backtrace:**

```bash
# Run with full backtrace
rails test test/models/user_test.rb --backtrace
```

**3. Run Single Test with Debug:**

```bash
# Enable debug mode
DEBUG=true rails test test/models/user_test.rb -n test_calculate_mastery_score
```

**4. Check Database State:**

```ruby
test "creates test session" do
  user = users(:learner)

  # Inspect before
  puts "Before: #{TestSession.count}"

  session = TestSession.create!(user: user, study_material: study_materials(:cert_guide))

  # Inspect after
  puts "After: #{TestSession.count}"
  puts "Session: #{session.inspect}"

  assert session.persisted?
end
```

---

## CI/CD Integration

### GitHub Actions Configuration

```yaml
# .github/workflows/test.yml
name: Test Suite

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest

    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
      - uses: actions/checkout@v4

      - name: Setup Ruby
        uses: ruby/setup-ruby@v1
        with:
          bundler-cache: true

      - name: Setup Database
        run: |
          bundle exec rails db:create
          bundle exec rails db:schema:load

      - name: Run Unit Tests (Parallel)
        run: bundle exec rails test test/unit/

      - name: Run Integration Tests (Parallel)
        run: bundle exec rails test test/integration/

      - name: Run System Tests (Sequential)
        run: bundle exec rails test:system

      - name: Report Coverage
        uses: codecov/codecov-action@v3
```

---

## Test Coverage Goals

### Minimum Coverage Requirements

- **Unit Tests:** 90% code coverage
- **Integration Tests:** 80% critical paths
- **System Tests:** 100% user journeys

### Measuring Coverage

```bash
# Run with SimpleCov
COVERAGE=true rails test

# View report
open coverage/index.html
```

### Coverage Configuration

```ruby
# test/test_helper.rb
if ENV['COVERAGE']
  require 'simplecov'

  SimpleCov.start 'rails' do
    add_filter '/test/'
    add_filter '/config/'

    add_group 'Models', 'app/models'
    add_group 'Controllers', 'app/controllers'
    add_group 'Services', 'app/services'
    add_group 'Jobs', 'app/jobs'

    minimum_coverage 90
  end
end
```

---

## Best Practices Summary

### ğŸš¨ ìµœìš°ì„  ì›ì¹™: ëê¹Œì§€ í…ŒìŠ¤íŠ¸ ì‹¤í–‰

**ëª¨ë“  ì‘ì—…ì˜ ìµœì¢… ë‹¨ê³„:**

```bash
# 1. í…ŒìŠ¤íŠ¸ ì‹¤í–‰
rails test

# 2. ê²°ê³¼ í™•ì¸ (ëê¹Œì§€!)
# - í†µê³¼í•œ í…ŒìŠ¤íŠ¸ ìˆ˜
# - ì‹¤íŒ¨í•œ í…ŒìŠ¤íŠ¸ ìˆ˜
# - ì—ëŸ¬ ë©”ì‹œì§€

# 3. ê²°ê³¼ ë¬¸ì„œí™”
echo "í…ŒìŠ¤íŠ¸ ê²°ê³¼: X passed, Y failed" > test-results.txt

# 4. ì‹¤íŒ¨ê°€ ìˆìœ¼ë©´ ìˆ˜ì • í›„ ë‹¤ì‹œ 1ë²ˆë¶€í„°
```

**ì ˆëŒ€ í•˜ì§€ ë§ì•„ì•¼ í•  ê²ƒ:**
- âŒ "ìˆ˜ì •í–ˆìœ¼ë‹ˆ ì•„ë§ˆ ë  ê²ƒ" ì¶”ì¸¡
- âŒ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì—†ì´ "ì™„ë£Œ" ë³´ê³ 
- âŒ ì¼ë¶€ë§Œ ì‹¤í–‰í•˜ê³  ë‚˜ë¨¸ì§€ëŠ” "ë‚˜ì¤‘ì—"
- âŒ ì‹¤íŒ¨ ë¬´ì‹œí•˜ê³  ë‹¤ìŒ ì‘ì—… ì§„í–‰

---

### DO

- âœ… **ëê¹Œì§€ í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ í™•ì¸í•  ê²ƒ** â­ ìµœìš°ì„ !
- âœ… **í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ ì‹œ ì¦‰ì‹œ ìˆ˜ì •í•˜ê³  ì¬ì‹¤í–‰í•  ê²ƒ** â­ í•„ìˆ˜!
- âœ… **ê²°ê³¼ë¥¼ ë¬¸ì„œí™”í•˜ê³  ê³µìœ í•  ê²ƒ** â­ í•„ìˆ˜!
- âœ… Write tests before implementing features
- âœ… Keep tests isolated and independent
- âœ… Use descriptive test names
- âœ… Test one behavior per test
- âœ… Clean up test data in teardown
- âœ… Run tests frequently during development
- âœ… Clear caches before testing after changes
- âœ… Group tests by isolation level
- âœ… Use parallel execution for speed

### DON'T

- âŒ **í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì—†ì´ "ì™„ë£Œ" ë³´ê³ í•˜ì§€ ë§ ê²ƒ** â­ ì ˆëŒ€ ê¸ˆì§€!
- âŒ **"ì•„ë§ˆ ë  ê²ƒ"ì´ë¼ê³  ì¶”ì¸¡í•˜ì§€ ë§ ê²ƒ** â­ ì ˆëŒ€ ê¸ˆì§€!
- âŒ **í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ë¥¼ ë¬´ì‹œí•˜ê³  ë‹¤ìŒ ì‘ì—… ì§„í–‰í•˜ì§€ ë§ ê²ƒ** â­ ì ˆëŒ€ ê¸ˆì§€!
- âŒ **ì¼ë¶€ë§Œ í…ŒìŠ¤íŠ¸í•˜ê³  ë‚˜ë¨¸ì§€ëŠ” "ë‚˜ì¤‘ì—"ë¼ê³  ë¯¸ë£¨ì§€ ë§ ê²ƒ**
- âŒ Share mutable state between tests
- âŒ Depend on test execution order
- âŒ Use sleep() for timing (use proper waits)
- âŒ Skip cache clearing after changes
- âŒ Mix parallel-safe and sequential tests
- âŒ Test implementation details (test behavior)
- âŒ Leave commented-out tests
- âŒ Commit with failing tests

---

## Quick Reference Commands

```bash
# Run all tests in parallel
rails test

# Run specific test file
rails test test/models/user_test.rb

# Run single test by name
rails test test/models/user_test.rb -n test_validates_email

# Run tests matching pattern
rails test test/models/**/*_test.rb

# Run with verbose output
rails test --verbose

# Clean restart workflow
pkill -f rails && rm -rf tmp/cache/* && rails test

# Check test status
echo $?  # 0 = passed, non-zero = failed
```

---

## Troubleshooting Guide

### Common Issues

**Tests pass individually but fail in suite:**
- Check for shared state pollution
- Verify database transactions are working
- Look for file system conflicts
- Review test execution order

**Tests flaky/intermittent failures:**
- Remove timing dependencies (sleep)
- Use proper async wait mechanisms
- Check for race conditions
- Verify external service mocks

**Slow test suite:**
- Profile tests: `rails test --profile`
- Move to faster test category if possible
- Use fixtures instead of factories
- Mock external services
- Increase parallel workers

**Cache-related false positives:**
- Always clear caches after code changes
- Kill all running processes
- Verify file contents were saved
- Use clean restart protocol

---

## Additional Resources

- [Minitest Documentation](https://github.com/minitest/minitest)
- [Rails Testing Guide](https://guides.rubyonrails.org/testing.html)
- [FactoryBot Documentation](https://github.com/thoughtbot/factory_bot)
- [SimpleCov Coverage Tool](https://github.com/simplecov-ruby/simplecov)

---

**Remember:** TDD is not just about writing testsâ€”it's about designing better code through test-first thinking. Let your tests guide your implementation toward simpler, more maintainable solutions.
